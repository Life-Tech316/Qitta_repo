---
title: 【データ分析基盤】Azure Data Factory(ADF)について概要を整理してみた
tags:
  - Azure
  - AzureBatch
  - DataFactory
private: false
updated_at: '2025-06-05T17:15:30+09:00'
id: 864d8e1a6058ed308b36
organization_url_name: null
slide: false
ignorePublish: false
---
## AzureDataFactory(ADF)とは何か
　でーた分析基盤のプロジェクトにてAzureのADFを使用したので整理していく。AzureのADFは下記の公式マニュアルで説明されている。

https://learn.microsoft.com/ja-jp/azure/data-factory/introduction


>Azure Data Factory は、このようなデータ シナリオを解決するプラットフォームです。 クラウドベースの ETL およびデータ統合サービスを通じて、データの移動と変換を大規模に制御するデータ ドリブンのワークフローを作成できます。 Azure Data Factory を使えば、各種のデータ ストアからデータを取り込むことができるデータ主導型のワークフロー (パイプライン) を作成し、スケジューリングできます。 コンピューティング サービス (Azure HDInsight Hadoop、Azure Databricks、Azure SQL Database など) やデータ フローを使用してデータを変換する複雑な ETL プロセスを視覚的に作成できます。

上記のように記載されており、データを統合管理するクラウドのプラットフォームである。
プロジェクトでは、AzureのBlobに配置されたファイルを整形して、SnowFlakeに登録するETLジョブをADFを使用して構築ていました。


## ADFの実行方法について
ADFの実行方法は下記のサイトでも説明されているが「デバック」ボタンを押すと
パイプラインが実行されて「出力」タブに「パイプライン」を構成する「アクティビティ」の状態が表示される。

https://learn.microsoft.com/ja-jp/azure/data-factory/concepts-pipeline-execution-triggers

「アクティビティ」には、実行時のIDが振られ
そのIDをAzureバッチのログなどで確認すると、stderrやstdoutなどを確認することもできる。

## ADFのアクティビティの設定について
　パイプの下には、カスタムプロパティを定義できる部分があり、それぞれの「アクティビティ」で
 - どのようなコマンドを実行するか?
 - どのリソースをインプットにするか?

などを定義することができる。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/381629/79a7f2e0-0685-4b06-8638-4dd7eea7d4a4.png)

Azure Batchというタブもあり、このタブでAzureBatchのリンクサービスを指定する。このBatchのサービスで定義されているプール上でパイプラインの処理が動作するイメージである。※プールにはVM(仮想インスタンス)の数やスペックなどが定義されている。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/381629/2ca7ba41-cb02-4d1f-8ba3-14bf48aaeb31.png)


