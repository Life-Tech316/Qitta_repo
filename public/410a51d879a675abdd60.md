---
title: ビッグデータ時代の必須スキル　Hadoop/Spark/Kafkaの超概要についての振り返りについて
tags:
  - データサイエンス
  - ビッグデータ
  - '#Hadoop'
  - '#Spark'
private: false
updated_at: '2025-02-17T12:32:54+09:00'
id: 410a51d879a675abdd60
organization_url_name: null
slide: false
ignorePublish: false
---
# はじめに
　ビッグデータが広く普及する現代、データ処理の効率化は不可欠です。その解決策の一つが「並列分散処理基盤」です。本記事では、Hadoop、Spark、Kafkaといった主要なオープンソース技術を中心に、並列分散処理基盤の基本から応用までを詳しく解説します。初心者でもわかりやすいように、各技術の概要と活用事例、導入時の注意点など簡単に整理していきます。

## 1. 並列分散処理とは
 並列分散処理とは、「データを複数のサーバに分散して蓄積・処理する手法」です。大規模なデータ（ビッグデータ）の処理を効率化し、数分から数時間で現実的な時間内に処理を完了することができます。

### 単体サーバでの限界:
大規模データの保管: 単一サーバのディスク容量には限界があり、ビッグデータを保管できない。
処理時間の問題: 単体サーバではデータ処理に長時間を要するため、現実的な利用が難しい。

### 並列分散処理の必要性:
ビッグデータの保管と迅速な処理を行うためには、複数のサーバを組み合わせて処理する並列分散処理が必要不可欠です。
## 2. 並列分散処理基盤の進化
　オープンソースの並列分散処理基盤の歴史はHadoopの誕生に始まります。その後、用途に応じてさまざまなプロダクトが登場し、多様なニーズに対応するよう進化してきました。

### Hadoopの登場
Hadoopは、Googleが発表したGFSやMapReduceの技術に基づいて開発されたオープンソースの分散処理フレームワークです。巨大なデータセットを数時間単位で処理するためのバッチ処理を主な目的としています。

### 新たなニーズへの対応
Hadoopの登場後、分散処理基盤の用途は多様化。リアルタイム処理など、より低レイテンシでのデータ処理が求められるようになりました。これにより、**Spark**や**Kafka**など、Hadoopの限界を補完するプロダクトが登場しました。

## 3. Hadoopとは
Hadoopは、大規模なデータを並列分散処理するためのフレームワークであり、次の2つの役割を担っています。

#### データの保存
複数台のサーバにデータを分散して保存し、ディスクのスループットを向上させます。

#### データの処理
MapReduceを用いて、複数のサーバで並列処理を行います。しかし、**繰り返しの多い処理や複雑な処理にはやや不向き**です。Hadoopの登場により、現実的なコストで大規模データの処理が可能となりましたが、処理の効率化やリアルタイム性においては制約が存在します。

## 4. Sparkとは
Sparkは、Hadoopの弱点であった繰り返し処理や複雑な処理を高速化するために開発されたフレームワークです。

### 特徴
メモリ上での処理を行うことで、ディスクI/Oを削減し、高速な処理を実現。
処理計画を事前に最適化することで、リソースの効率的な利用を可能にしています。

### 多機能性
SQLを使ったデータクエリや機械学習、ストリーム処理など、多様なデータ処理に対応。
メリットとしては、SQLに対応しており、専門知識がなくても分散処理アプリケーションの開発が可能。
Sparkは、複雑な処理を高速かつ効率的に行うことができるため、幅広いデータ処理に利用されています。

## 5. Kafkaとは
Kafkaは、ストリーム処理をサポートするためのメッセージングシステムです。

### 役割
データ生成元から収集したデータを、処理基盤に効率よく転送します。
データを失わないようにディスクに記録し、必要に応じて処理側がデータを取り出せるようにします。
### 特徴
高いスループットを持ち、大量のデータをリアルタイムで処理するための基盤として機能します。
Kafkaは、リアルタイムデータ処理において欠かせない要素として、データの受け渡しを効率的に行う役割を果たしています。

## 6. 活用事例
### 6.1. 事例1: 賃貸経営におけるデータ分析（大東建託）
背景
賃貸経営におけるリスクを可視化し、戦略的な意思決定を行うために大量の運営データを分析する必要がありました。
導入後の効果:
Hadoopを導入し、大規模データを用いたリアルタイムな分析を実現。
BIツールと連携し、迅速かつ簡単に収益傾向やリスク予測を行えるようになりました。

### 6.2. 事例2: ECサイトのリアルタイム分析（リクルートライフスタイル）
背景:
ECサイトにおいて、ユーザーのリアルタイムな行動を把握し、購買意欲を高めるための情報提供が必要でした。
導入後の効果:
KafkaとSparkを活用し、ユーザーの閲覧ログをリアルタイムに収集・分析。
「現在何人が閲覧中」「何人が予約中」といった情報をリアルタイムで表示し、購買行動を促進しました。

### 7. 導入時のポイント
並列分散処理基盤を導入する際には、以下の3つのポイントを考慮する必要があります。

データ量と処理量:
大規模なデータを処理するための基盤であるため、少量のデータには向きません。
サーバの台数による調整:
スケールアウトが容易であるため、サーバの台数を増やして性能を調整できます。
適材適所の利用:
Hadoop、Spark、Kafkaにはそれぞれ得意な領域があるため、用途に応じて使い分けることが重要です。

### まとめ
本記事では、**「Hadoop、Spark、Kafka」**を中心に、並列分散処理基盤の基礎から概要なでの説明をしました。データ量の増加に伴い、ビッグデータを効率的に処理するための技術はますます重要になっています。これらの技術を適切に活用することで、大規模なデータ分析やリアルタイムなデータ処理を実現し、ビジネスにおける意思決定をサポートすることが可能です。
