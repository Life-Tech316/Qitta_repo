---
title: 【機械学習/MLフレームワーク】LightGBMとは何かについて概要を整理してみた。
tags:
  - 機械学習
  - アンサンブル学習
private: false
updated_at: '2025-06-05T17:25:00+09:00'
id: 6aa31c5910c0755a9b09
organization_url_name: null
slide: false
ignorePublish: false
---
# 1. LightGBMとは何か
まず、LightGBMの概要を説明します。

**LightGBM**は、Microsoftが開発した勾配ブースティング※1 のフレームワークです。特に、大規模なデータセットを効率的に処理するために設計されており、分類、回帰、ランキング問題などに広く利用されています。

※1 勾配ブースティングは、決定木をベースにしたアンサンブル学習法の一つである。

 主な特徴:
- 高速な学習と予測速度
- メモリ使用量の低さ
- 大規模データに強い
- 欠損値やカテゴリ変数の取り扱いに優れている​

# 2. LightGBMのアルゴリズム構成
LightGBMは、従来の勾配ブースティングアルゴリズムを改良し、特に以下の点で優れています。

## 2.1. ヒストグラムベースの決定木学習
LightGBMは、データをビン（bin）に分割し、連続変数を効率的に処理します。このヒストグラムアプローチにより、他の勾配ブースティングツールよりも計算コストを削減できます。

## 2.2. Leaf-wise（リーフ重視）の木構造
通常の決定木はレベルごとに分割されますが、LightGBMではリーフごとに分割されます。これにより、より深いツリーが作成され、予測の精度が向上する反面、過学習（オーバーフィッティング）のリスクも増します。

## 2.3. 勾配ブースティングとバギングの組み合わせ
LightGBMは勾配ブースティングにバギング（ブートストラップ）を組み合わせることで、モデルの安定性と精度を向上させます。これにより、ノイズの多いデータや複雑なモデルにも強くなります​

## 2.4  LightGBMの実装例

``` python:python.py

import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# データの準備
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBM データセット作成
train_data = lgb.Dataset(X_train, label=y_train)

# ハイパーパラメータ設定
params = {
    'objective': 'binary',
    'boosting_type': 'gbdt',
    'metric': 'binary_logloss',
    'num_leaves': 31,
    'learning_rate': 0.05
}

# モデルの学習
model = lgb.train(params, train_data, num_boost_round=100)

# 予測
y_pred = model.predict(X_test)
y_pred = [1 if pred >= 0.5 else 0 for pred in y_pred]

# 精度の評価
print('Accuracy:', accuracy_score(y_test, y_pred))
```

## 4. LightGBMのメリットとデメリット
最後に、LightGBMのメリットとデメリットを整理します。

メリット:

大規模データの処理に強く、他の勾配ブースティング手法より高速
自動で欠損値処理を行う機能
カテゴリ変数のエンコーディングが不要
デメリット:

過学習しやすい（特にnum_leavesが大きい場合）
チューニングが必要なパラメータが多い
